{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = mnist['data'],mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.reshape(70000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 1)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x[0:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y[0:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x[60000:70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y[60000:70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batches=list()\n",
    "for i in range(120):\n",
    "    mini_batches.append((x_train[i*500:(i+1)*500],y_train[i*500:(i+1)*500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10000)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 10000)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(arr):\n",
    "    d=1/(1+np.exp(-arr))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    params -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    #np.random.seed(2) # we set up a seed so that your output matches ours although the initialization is random.\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    W1 = np.random.randn(n_h,n_x)*0.001\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h)*0.001\n",
    "    b2 = np.zeros((n_y,1))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    \n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- input data of size (n_x, m)\n",
    "    parameters -- python dictionary containing your parameters (output of initialization function)\n",
    "    \n",
    "    Returns:\n",
    "    A2 -- The sigmoid output of the second activation\n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    \"\"\"\n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    W1=parameters[\"W1\"]\n",
    "    b1=parameters[\"b1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    b2=parameters[\"b2\"]\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Implement Forward Propagation to calculate A2 (probabilities)\n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    Z1 = np.dot(W1,X)+b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2,A1)+b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    \n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y, parameters,lambda_):\n",
    "    \"\"\"\n",
    "    Computes the cross-entropy cost given in equation (13)\n",
    "    \n",
    "    Arguments:\n",
    "    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)\n",
    "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "    parameters -- python dictionary containing your parameters W1, b1, W2 and b2\n",
    "    [Note that the parameters argument is not used in this function, \n",
    "    but the auto-grader currently expects this parameter.\n",
    "    Future version of this notebook will fix both the notebook \n",
    "    and the auto-grader so that `parameters` is not needed.\n",
    "    For now, please include `parameters` in the function signature,\n",
    "    and also when invoking this function.]\n",
    "    \n",
    "    Returns:\n",
    "    cost -- cross-entropy cost given equation (13)\n",
    "    \n",
    "    \"\"\"\n",
    "    W1=parameters['W1']\n",
    "    W2=parameters['W2']\n",
    "    m = Y.shape[1] # number of example\n",
    "    # Compute the cross-entropy cost\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    cost = -1/m *np.sum(np.sum(((Y*np.log(A2)+(1-Y)*np.log(1-A2))))) + (lambda_/(2*m))*(np.sum(np.sum(W1*W1))+np.sum(np.sum(W2*W2)))    \n",
    "                                                                        \n",
    "    '''cost = float(np.squeeze(cost))  # makes sure cost is the dimension we expect. \n",
    "                                    # E.g., turns [[17]] into 17 \n",
    "    assert(isinstance(cost, float))'''\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y,lambda_):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation using the instructions above.\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing our parameters \n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
    "    X -- input data of shape (2, number of examples)\n",
    "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    grads -- python dictionary containing your gradients with respect to different parameters\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    W1=parameters[\"W1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    ### END CODE HERE ###\n",
    "        \n",
    "    # Retrieve also A1 and A2 from dictionary \"cache\".\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    A1 = cache[\"A1\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backward propagation: calculate dW1, db1, dW2, db2. \n",
    "    ### START CODE HERE ### (≈ 6 lines of code, corresponding to 6 equations on slide above)\n",
    "    \n",
    "    dZ2 = A2-Y;\n",
    "    dW2 = 1/m *np.dot(dZ2,A1.T) +(lambda_/m)*W2\n",
    "    db2 = 1/m *np.sum(dZ2,axis=1,keepdims=True)\n",
    "    dZ1 = np.dot(W2.T,dZ2)*(1-A1*A1)\n",
    "    dW1 = 1/m *np.dot(dZ1,X.T) +(lambda_/m)*W1\n",
    "    db1 =1/m *np.sum(dZ1,axis=1,keepdims=True)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2,}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate = 0.1):\n",
    "    \"\"\"\n",
    "    Updates parameters using the gradient descent update rule given above\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    \"\"\"\n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    W1=parameters[\"W1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    b1=parameters[\"b1\"]\n",
    "    b2=parameters[\"b2\"]\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Retrieve each gradient from the dictionary \"grads\"\n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "    \n",
    "    ## END CODE HERE ###\n",
    "    \n",
    "    # Update rule for each parameter\n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    W1 = W1-learning_rate*dW1\n",
    "    b1 = b1-learning_rate*db1\n",
    "    W2 = W2-learning_rate*dW2\n",
    "    b2 = b2-learning_rate*db2\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_adam\n",
    "\n",
    "def initialize_adam(parameters) :\n",
    "    \"\"\"\n",
    "    Initializes v and s as two python dictionaries with:\n",
    "                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n",
    "                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters.\n",
    "                    parameters[\"W\" + str(l)] = Wl\n",
    "                    parameters[\"b\" + str(l)] = bl\n",
    "    \n",
    "    Returns: \n",
    "    v -- python dictionary that will contain the exponentially weighted average of the gradient.\n",
    "                    v[\"dW\" + str(l)] = ...\n",
    "                    v[\"db\" + str(l)] = ...\n",
    "    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.\n",
    "                    s[\"dW\" + str(l)] = ...\n",
    "                    s[\"db\" + str(l)] = ...\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    # Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\n",
    "    for l in range(2):\n",
    "    ### START CODE HERE ### (approx. 4 lines)\n",
    "        v[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\" + str(l+1)].shape)\n",
    "        v[\"db\" + str(l+1)] = np.zeros(parameters[\"b\" + str(l+1)].shape)\n",
    "        s[\"dW\" + str(l+1)] = np.zeros(parameters[\"W\" + str(l+1)].shape)\n",
    "        s[\"db\" + str(l+1)] = np.zeros(parameters[\"b\" + str(l+1)].shape)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: update_parameters_with_adam\n",
    "\n",
    "def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,\n",
    "                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n",
    "    \"\"\"\n",
    "    Update parameters using Adam\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters:\n",
    "                    parameters['W' + str(l)] = Wl\n",
    "                    parameters['b' + str(l)] = bl\n",
    "    grads -- python dictionary containing your gradients for each parameters:\n",
    "                    grads['dW' + str(l)] = dWl\n",
    "                    grads['db' + str(l)] = dbl\n",
    "    v -- Adam variable, moving average of the first gradient, python dictionary\n",
    "    s -- Adam variable, moving average of the squared gradient, python dictionary\n",
    "    learning_rate -- the learning rate, scalar.\n",
    "    beta1 -- Exponential decay hyperparameter for the first moment estimates \n",
    "    beta2 -- Exponential decay hyperparameter for the second moment estimates \n",
    "    epsilon -- hyperparameter preventing division by zero in Adam updates\n",
    "\n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    v -- Adam variable, moving average of the first gradient, python dictionary\n",
    "    s -- Adam variable, moving average of the squared gradient, python dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    #L = len(parameters) // 2                 # number of layers in the neural networks\n",
    "    v_corrected = {}                         # Initializing first moment estimate, python dictionary\n",
    "    s_corrected = {}                         # Initializing second moment estimate, python dictionary\n",
    "    \n",
    "    # Perform Adam update on all parameters\n",
    "    for l in range(2):\n",
    "        # Moving average of the gradients. Inputs: \"v, grads, beta1\". Output: \"v\".\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        v[\"dW\" + str(l+1)] = beta1*v[\"dW\" + str(l+1)]+(1-beta1)*grads['dW' + str(l+1)]\n",
    "        v[\"db\" + str(l+1)] = beta1*v[\"db\" + str(l+1)]+(1-beta1)*grads['db' + str(l+1)]\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Compute bias-corrected first moment estimate. Inputs: \"v, beta1, t\". Output: \"v_corrected\".\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)]/(1-beta1**t)\n",
    "        v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)]/(1-beta1**t)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Moving average of the squared gradients. Inputs: \"s, grads, beta2\". Output: \"s\".\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        s[\"dW\" + str(l+1)] = beta2*s[\"dW\" + str(l+1)]+(1-beta2)*grads['dW' + str(l+1)]*grads['dW' + str(l+1)]\n",
    "        s[\"db\" + str(l+1)] = beta2*s[\"db\" + str(l+1)]+(1-beta2)*grads['db' + str(l+1)]*grads['db' + str(l+1)]\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate. Inputs: \"s, beta2, t\". Output: \"s_corrected\".\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)]/(1-beta2**t)\n",
    "        s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)]/(1-beta2**t)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Update parameters. Inputs: \"parameters, learning_rate, v_corrected, s_corrected, epsilon\". Output: \"parameters\".\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)]-learning_rate*(v_corrected[\"dW\" + str(l+1)]/(s_corrected[\"dW\" + str(l+1)]**(1/2)+epsilon))\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)]-learning_rate*(v_corrected[\"db\" + str(l+1)]/(s_corrected[\"db\" + str(l+1)]**(1/2)+epsilon))\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    return parameters, v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(mini_batches, n_h, num_iterations = 1000, print_cost=False,lambda_=1.2,learning_rate = 0.1):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- dataset of shape (2, number of examples)\n",
    "    Y -- labels of shape (1, number of examples)\n",
    "    n_h -- size of the hidden layer\n",
    "    num_iterations -- Number of iterations in gradient descent loop\n",
    "    print_cost -- if True, print the cost every 1000 iterations\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    parameters = initialize_parameters(784, n_h, 10)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    costs=[]\n",
    "    for i in range(0, num_iterations):\n",
    "        cost=0\n",
    "        for j in range(120):\n",
    "            \n",
    "            mini_batch_x,mini_batch_y=mini_batches[j]\n",
    "            ### START CODE HERE ### (≈ 4 lines of code)\n",
    "            # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "            X=mini_batch_x.T\n",
    "            y=mini_batch_y.T\n",
    "            Y=np.zeros((10,500))\n",
    "            for jj in range (10):\n",
    "                for ii in range(500):\n",
    "                    if(y[0][ii]==str(jj)):\n",
    "                        Y[jj][ii]=1\n",
    "            A2, cache = forward_propagation(X, parameters)\n",
    "\n",
    "            # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
    "            cost += compute_cost(A2, Y, parameters,lambda_)\n",
    "\n",
    "            # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "            grads = backward_propagation(parameters, cache, X, Y,lambda_)\n",
    "\n",
    "            # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "            parameters = update_parameters(parameters, grads,learning_rate = 0.1)\n",
    "\n",
    "            ### END CODE HERE ###\n",
    "        costs.append(cost/60000)\n",
    "            # Print the cost every 1000 iterations\n",
    "        if print_cost and i % 5 == 0:\n",
    "            print (\"Cost after iteration :\",i,\" is \",cost)\n",
    "        if i%50==0:\n",
    "            learning_rate=learning_rate/2\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (x1,000)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration : 0  is  3.21330734049018\n",
      "Cost after iteration : 5  is  1.5737072454013608\n",
      "Cost after iteration : 10  is  1.1387863257995063\n",
      "Cost after iteration : 15  is  0.9980830653220325\n",
      "Cost after iteration : 20  is  0.9265914169684832\n",
      "Cost after iteration : 25  is  0.878734119226452\n",
      "Cost after iteration : 30  is  0.861756047883463\n",
      "Cost after iteration : 35  is  0.8552211675616873\n",
      "Cost after iteration : 40  is  0.8513823016095828\n",
      "Cost after iteration : 45  is  0.8465425518019067\n",
      "Cost after iteration : 50  is  0.8308289987654307\n",
      "Cost after iteration : 55  is  0.812428401083317\n",
      "Cost after iteration : 60  is  0.7997467677398034\n",
      "Cost after iteration : 65  is  0.7892781481058989\n",
      "Cost after iteration : 70  is  0.7807873117624367\n",
      "Cost after iteration : 75  is  0.7748898547915806\n",
      "Cost after iteration : 80  is  0.7707148831843236\n",
      "Cost after iteration : 85  is  0.7671341261025164\n",
      "Cost after iteration : 90  is  0.763391787311869\n",
      "Cost after iteration : 95  is  0.7589007738587026\n",
      "Cost after iteration : 100  is  0.7531296334928086\n",
      "Cost after iteration : 105  is  0.7475579527843018\n",
      "Cost after iteration : 110  is  0.7433081110211159\n",
      "Cost after iteration : 115  is  0.7399781170825936\n",
      "Cost after iteration : 120  is  0.7369692810151816\n",
      "Cost after iteration : 125  is  0.7336322000813057\n",
      "Cost after iteration : 130  is  0.7294200221227968\n",
      "Cost after iteration : 135  is  0.7251504059421241\n",
      "Cost after iteration : 140  is  0.7217404450867351\n",
      "Cost after iteration : 145  is  0.7190527446633874\n",
      "Cost after iteration : 150  is  0.7167967041753892\n",
      "Cost after iteration : 155  is  0.714735297851522\n",
      "Cost after iteration : 160  is  0.7124863786171404\n",
      "Cost after iteration : 165  is  0.7102808779134298\n",
      "Cost after iteration : 170  is  0.70799841267698\n",
      "Cost after iteration : 175  is  0.7056117242297805\n",
      "Cost after iteration : 180  is  0.7035017126055099\n",
      "Cost after iteration : 185  is  0.7018445422547163\n",
      "Cost after iteration : 190  is  0.7004934878873749\n",
      "Cost after iteration : 195  is  0.699178453999769\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = nn_model(mini_batches, 15, num_iterations=200, print_cost=True,lambda_=1.2,learning_rate = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2, cache = forward_propagation(x_train.T, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.37700331e-02, 9.81509024e-01, 1.13531240e-03, ...,\n",
       "        1.41976993e-03, 6.43699967e-03, 7.23984440e-02],\n",
       "       [8.50981799e-04, 8.04250543e-05, 1.37947069e-03, ...,\n",
       "        6.62005606e-03, 1.15211133e-03, 2.72807087e-03],\n",
       "       [7.17173049e-04, 6.21995527e-03, 2.87569250e-02, ...,\n",
       "        4.67249303e-05, 9.08391799e-03, 3.59421945e-03],\n",
       "       ...,\n",
       "       [1.95333790e-01, 1.22384385e-02, 1.08918335e-01, ...,\n",
       "        5.69995488e-03, 4.19943430e-03, 9.20348970e-04],\n",
       "       [2.33523064e-04, 1.02045128e-02, 1.84992624e-03, ...,\n",
       "        1.72635114e-02, 1.16754181e-03, 9.11598348e-01],\n",
       "       [1.10309048e-03, 1.34746137e-03, 8.01033716e-03, ...,\n",
       "        3.63455994e-03, 5.52678069e-03, 7.83655641e-02]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(10):\n",
    "    for i in range(60000):\n",
    "        if(A2[j][i]>=0.5):\n",
    "            A2[j][i]=1\n",
    "        else:\n",
    "            A2[j][i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2=A2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.zeros((1,60000))\n",
    "for i in range(60000):\n",
    "    c[0][i]=np.where(A2[i] == np.amax(A2[i]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 0., 4., ..., 5., 6., 8.]])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['5', '0', '4', ..., '5', '6', '8']], dtype=object)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=0\n",
    "m=60000\n",
    "for i in range(60000):\n",
    "    if(c[0][i]==int(y_train.T[0][i])):\n",
    "        s=s+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53058"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8843"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2, cache = forward_propagation(x_test, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(10):\n",
    "    for i in range(10000):\n",
    "        if(A2[j][i]>=0.5):\n",
    "            A2[j][i]=1\n",
    "        else:\n",
    "            A2[j][i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2=A2.T\n",
    "c=np.zeros((1,10000))\n",
    "for i in range(10000):\n",
    "    c[0][i]=np.where(A2[i] == np.amax(A2[i]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7., 2., 1., ..., 4., 5., 6.]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['7', '2', '1', ..., '4', '5', '6']], dtype=object)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=0\n",
    "m=10000\n",
    "for i in range(10000):\n",
    "    if(c[0][i]==int(y_test[0][i])):\n",
    "        s=s+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8828"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8828"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(mini_batches,learning_rate = 0.0007,beta = 0.9,beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_iterations = 200,lambda_=1.2, print_cost = True):\n",
    "    \"\"\"\n",
    "    3-layer neural network model which can be run in different optimizer modes.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (2, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    layers_dims -- python list, containing the size of each layer\n",
    "    learning_rate -- the learning rate, scalar.\n",
    "    mini_batch_size -- the size of a mini batch\n",
    "    beta -- Momentum hyperparameter\n",
    "    beta1 -- Exponential decay hyperparameter for the past gradients estimates \n",
    "    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates \n",
    "    epsilon -- hyperparameter preventing division by zero in Adam updates\n",
    "    num_epochs -- number of epochs\n",
    "    print_cost -- True to print the cost every 1000 epochs\n",
    "\n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    \"\"\"\n",
    "     #number of layers in the neural networks\n",
    "    costs = []                       # to keep track of the cost\n",
    "    t = 0                            # number of training examples\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(784, 800, 10)\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    v, s = initialize_adam(parameters)\n",
    "    \n",
    "    # Optimization loop\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        cost_total = 0\n",
    "        \n",
    "        for j in range(120):\n",
    "            \n",
    "            mini_batch_x,mini_batch_y=mini_batches[j]\n",
    "            ### START CODE HERE ### (≈ 4 lines of code)\n",
    "            # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "            X=mini_batch_x.T\n",
    "            y=mini_batch_y.T\n",
    "            Y=np.zeros((10,500))\n",
    "            for jj in range (10):\n",
    "                for ii in range(500):\n",
    "                    if(y[0][ii]==str(jj)):\n",
    "                        Y[jj][ii]=1\n",
    "\n",
    "\n",
    "            # Forward propagation\n",
    "            A2, caches = forward_propagation(X, parameters)\n",
    "\n",
    "            # Compute cost and add to the cost total\n",
    "            cost_total += compute_cost(A2, Y,parameters,lambda_)\n",
    "\n",
    "            # Backward propagation\n",
    "            grads = backward_propagation(parameters, caches, X, Y,lambda_)\n",
    "\n",
    "            # Update parameters\n",
    "            t = t + 1 # Adam counter\n",
    "            parameters, v, s = update_parameters_with_adam(parameters, grads, v, s,\n",
    "                                                               t, learning_rate, beta1, beta2,  epsilon)\n",
    "        cost_avg = cost_total / m\n",
    "        \n",
    "        # Print the cost every 1000 epoch\n",
    "        print (\"Cost after epoch %i: %f\" %(i, cost_avg))\n",
    "        if print_cost and i % 10 == 0:\n",
    "            costs.append(cost_avg)\n",
    "                \n",
    "    # plot the cost\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epochs (per 100)')\n",
    "    plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.032251\n",
      "Cost after epoch 1: 0.012673\n",
      "Cost after epoch 2: 0.010317\n",
      "Cost after epoch 3: 0.009543\n",
      "Cost after epoch 4: 0.009049\n",
      "Cost after epoch 5: 0.008670\n",
      "Cost after epoch 6: 0.008365\n",
      "Cost after epoch 7: 0.008115\n",
      "Cost after epoch 8: 0.007906\n",
      "Cost after epoch 9: 0.007730\n",
      "Cost after epoch 10: 0.007581\n",
      "Cost after epoch 11: 0.007455\n",
      "Cost after epoch 12: 0.007347\n",
      "Cost after epoch 13: 0.007253\n",
      "Cost after epoch 14: 0.007172\n",
      "Cost after epoch 15: 0.007102\n",
      "Cost after epoch 16: 0.007041\n",
      "Cost after epoch 17: 0.006987\n",
      "Cost after epoch 18: 0.006940\n",
      "Cost after epoch 19: 0.006898\n",
      "Cost after epoch 20: 0.006861\n",
      "Cost after epoch 21: 0.006827\n",
      "Cost after epoch 22: 0.006797\n",
      "Cost after epoch 23: 0.006769\n",
      "Cost after epoch 24: 0.006744\n",
      "Cost after epoch 25: 0.006722\n",
      "Cost after epoch 26: 0.006701\n",
      "Cost after epoch 27: 0.006682\n",
      "Cost after epoch 28: 0.006664\n",
      "Cost after epoch 29: 0.006648\n",
      "Cost after epoch 30: 0.006633\n",
      "Cost after epoch 31: 0.006618\n",
      "Cost after epoch 32: 0.006605\n",
      "Cost after epoch 33: 0.006593\n",
      "Cost after epoch 34: 0.006581\n",
      "Cost after epoch 35: 0.006571\n",
      "Cost after epoch 36: 0.006560\n",
      "Cost after epoch 37: 0.006551\n",
      "Cost after epoch 38: 0.006542\n",
      "Cost after epoch 39: 0.006533\n",
      "Cost after epoch 40: 0.006525\n",
      "Cost after epoch 41: 0.006517\n",
      "Cost after epoch 42: 0.006510\n",
      "Cost after epoch 43: 0.006502\n",
      "Cost after epoch 44: 0.006496\n",
      "Cost after epoch 45: 0.006489\n",
      "Cost after epoch 46: 0.006483\n",
      "Cost after epoch 47: 0.006477\n",
      "Cost after epoch 48: 0.006471\n",
      "Cost after epoch 49: 0.006465\n",
      "Cost after epoch 50: 0.006460\n",
      "Cost after epoch 51: 0.006455\n",
      "Cost after epoch 52: 0.006450\n",
      "Cost after epoch 53: 0.006445\n",
      "Cost after epoch 54: 0.006440\n",
      "Cost after epoch 55: 0.006435\n",
      "Cost after epoch 56: 0.006431\n",
      "Cost after epoch 57: 0.006427\n",
      "Cost after epoch 58: 0.006422\n",
      "Cost after epoch 59: 0.006418\n",
      "Cost after epoch 60: 0.006414\n",
      "Cost after epoch 61: 0.006410\n",
      "Cost after epoch 62: 0.006407\n",
      "Cost after epoch 63: 0.006403\n",
      "Cost after epoch 64: 0.006399\n",
      "Cost after epoch 65: 0.006396\n",
      "Cost after epoch 66: 0.006393\n",
      "Cost after epoch 67: 0.006389\n",
      "Cost after epoch 68: 0.006386\n",
      "Cost after epoch 69: 0.006383\n",
      "Cost after epoch 70: 0.006380\n",
      "Cost after epoch 71: 0.006377\n",
      "Cost after epoch 72: 0.006375\n",
      "Cost after epoch 73: 0.006372\n",
      "Cost after epoch 74: 0.006369\n",
      "Cost after epoch 75: 0.006367\n",
      "Cost after epoch 76: 0.006364\n",
      "Cost after epoch 77: 0.006362\n",
      "Cost after epoch 78: 0.006360\n",
      "Cost after epoch 79: 0.006357\n",
      "Cost after epoch 80: 0.006355\n",
      "Cost after epoch 81: 0.006353\n",
      "Cost after epoch 82: 0.006351\n",
      "Cost after epoch 83: 0.006349\n",
      "Cost after epoch 84: 0.006347\n",
      "Cost after epoch 85: 0.006345\n",
      "Cost after epoch 86: 0.006343\n",
      "Cost after epoch 87: 0.006341\n",
      "Cost after epoch 88: 0.006340\n",
      "Cost after epoch 89: 0.006338\n",
      "Cost after epoch 90: 0.006336\n",
      "Cost after epoch 91: 0.006335\n",
      "Cost after epoch 92: 0.006333\n",
      "Cost after epoch 93: 0.006332\n",
      "Cost after epoch 94: 0.006330\n",
      "Cost after epoch 95: 0.006329\n",
      "Cost after epoch 96: 0.006328\n",
      "Cost after epoch 97: 0.006326\n",
      "Cost after epoch 98: 0.006325\n",
      "Cost after epoch 99: 0.006324\n",
      "Cost after epoch 100: 0.006322\n",
      "Cost after epoch 101: 0.006321\n",
      "Cost after epoch 102: 0.006320\n",
      "Cost after epoch 103: 0.006318\n",
      "Cost after epoch 104: 0.006317\n",
      "Cost after epoch 105: 0.006316\n",
      "Cost after epoch 106: 0.006315\n",
      "Cost after epoch 107: 0.006313\n",
      "Cost after epoch 108: 0.006312\n",
      "Cost after epoch 109: 0.006311\n",
      "Cost after epoch 110: 0.006310\n",
      "Cost after epoch 111: 0.006309\n",
      "Cost after epoch 112: 0.006307\n",
      "Cost after epoch 113: 0.006306\n",
      "Cost after epoch 114: 0.006305\n",
      "Cost after epoch 115: 0.006304\n",
      "Cost after epoch 116: 0.006302\n",
      "Cost after epoch 117: 0.006301\n",
      "Cost after epoch 118: 0.006300\n",
      "Cost after epoch 119: 0.006299\n",
      "Cost after epoch 120: 0.006298\n",
      "Cost after epoch 121: 0.006297\n",
      "Cost after epoch 122: 0.006296\n",
      "Cost after epoch 123: 0.006295\n",
      "Cost after epoch 124: 0.006294\n",
      "Cost after epoch 125: 0.006293\n",
      "Cost after epoch 126: 0.006292\n",
      "Cost after epoch 127: 0.006292\n",
      "Cost after epoch 128: 0.006291\n",
      "Cost after epoch 129: 0.006290\n",
      "Cost after epoch 130: 0.006289\n",
      "Cost after epoch 131: 0.006288\n",
      "Cost after epoch 132: 0.006288\n",
      "Cost after epoch 133: 0.006287\n",
      "Cost after epoch 134: 0.006286\n",
      "Cost after epoch 135: 0.006285\n",
      "Cost after epoch 136: 0.006285\n",
      "Cost after epoch 137: 0.006284\n",
      "Cost after epoch 138: 0.006283\n",
      "Cost after epoch 139: 0.006283\n",
      "Cost after epoch 140: 0.006282\n",
      "Cost after epoch 141: 0.006281\n",
      "Cost after epoch 142: 0.006281\n",
      "Cost after epoch 143: 0.006280\n",
      "Cost after epoch 144: 0.006280\n",
      "Cost after epoch 145: 0.006279\n",
      "Cost after epoch 146: 0.006278\n",
      "Cost after epoch 147: 0.006278\n",
      "Cost after epoch 148: 0.006277\n",
      "Cost after epoch 149: 0.006277\n",
      "Cost after epoch 150: 0.006276\n",
      "Cost after epoch 151: 0.006275\n",
      "Cost after epoch 152: 0.006275\n",
      "Cost after epoch 153: 0.006274\n",
      "Cost after epoch 154: 0.006274\n",
      "Cost after epoch 155: 0.006273\n",
      "Cost after epoch 156: 0.006273\n",
      "Cost after epoch 157: 0.006272\n",
      "Cost after epoch 158: 0.006272\n",
      "Cost after epoch 159: 0.006271\n",
      "Cost after epoch 160: 0.006271\n",
      "Cost after epoch 161: 0.006270\n",
      "Cost after epoch 162: 0.006270\n",
      "Cost after epoch 163: 0.006269\n",
      "Cost after epoch 164: 0.006269\n",
      "Cost after epoch 165: 0.006268\n",
      "Cost after epoch 166: 0.006268\n",
      "Cost after epoch 167: 0.006267\n",
      "Cost after epoch 168: 0.006267\n",
      "Cost after epoch 169: 0.006266\n",
      "Cost after epoch 170: 0.006266\n",
      "Cost after epoch 171: 0.006266\n",
      "Cost after epoch 172: 0.006265\n",
      "Cost after epoch 173: 0.006265\n",
      "Cost after epoch 174: 0.006265\n",
      "Cost after epoch 175: 0.006264\n",
      "Cost after epoch 176: 0.006264\n",
      "Cost after epoch 177: 0.006263\n",
      "Cost after epoch 178: 0.006263\n",
      "Cost after epoch 179: 0.006262\n",
      "Cost after epoch 180: 0.006262\n",
      "Cost after epoch 181: 0.006262\n",
      "Cost after epoch 182: 0.006262\n",
      "Cost after epoch 183: 0.006261\n",
      "Cost after epoch 184: 0.006260\n",
      "Cost after epoch 185: 0.006260\n",
      "Cost after epoch 186: 0.006259\n",
      "Cost after epoch 187: 0.006259\n",
      "Cost after epoch 188: 0.006259\n",
      "Cost after epoch 189: 0.006258\n",
      "Cost after epoch 190: 0.006258\n",
      "Cost after epoch 191: 0.006258\n",
      "Cost after epoch 192: 0.006257\n",
      "Cost after epoch 193: 0.006256\n",
      "Cost after epoch 194: 0.006256\n",
      "Cost after epoch 195: 0.006256\n",
      "Cost after epoch 196: 0.006255\n",
      "Cost after epoch 197: 0.006255\n",
      "Cost after epoch 198: 0.006255\n",
      "Cost after epoch 199: 0.006254\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = model(mini_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2, cache = forward_propagation(x_train.T, parameters)\n",
    "for j in range(10):\n",
    "    for i in range(60000):\n",
    "        if(A2[j][i]>=0.5):\n",
    "            A2[j][i]=1\n",
    "        else:\n",
    "            A2[j][i]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2=A2.T\n",
    "c=np.zeros((1,60000))\n",
    "for i in range(60000):\n",
    "    c[0][i]=np.where(A2[i] == np.amax(A2[i]))[0][0]\n",
    "s=0\n",
    "m=60000\n",
    "for i in range(60000):\n",
    "    if(c[0][i]==int(y_train.T[0][i])):\n",
    "        s=s+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56424"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9404"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2, cache = forward_propagation(x_test, parameters)\n",
    "for j in range(10):\n",
    "    for i in range(10000):\n",
    "        if(A2[j][i]>=0.5):\n",
    "            A2[j][i]=1\n",
    "        else:\n",
    "            A2[j][i]=0\n",
    "A2=A2.T\n",
    "c=np.zeros((1,10000))\n",
    "for i in range(10000):\n",
    "    c[0][i]=np.where(A2[i] == np.amax(A2[i]))[0][0]\n",
    "s=0\n",
    "m=10000\n",
    "for i in range(10000):\n",
    "    if(c[0][i]==int(y_test[0][i])):\n",
    "        s=s+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9373"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9373"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('f1/W1.txt',parameters['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('f1/W2.txt',parameters['W2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('f1/b1.txt',parameters['b1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('f1/b2.txt',parameters['b2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['W1']=np.loadtxt('f1/W1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['W2']=np.loadtxt('f1/W2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['b2']=np.loadtxt('f1/b2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['b1']=np.loadtxt('f1/b1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['b2']=parameters['b2'].reshape((10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['b1']=parameters['b1'].reshape((800,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1=Image.open('0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=img.convert('L')\n",
    "img=img.resize((28,28))\n",
    "\n",
    "img=np.array(img)\n",
    "img=255-img\n",
    "img=img/255\n",
    "plt.imshow(img,cmap='gray')\n",
    "X=np.zeros((1,784))\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        X[0][i*28+j]=img[i][j]\n",
    "X=X.T\n",
    "A2,cache=forward_propagation(X,parameters)\n",
    "A2=A2.T\n",
    "c=np.where(A2[0] == np.amax(A2[0]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.70555838e-01, 3.94512458e-05, 1.03119623e-02, 2.47426252e-03,\n",
       "        5.82760190e-05, 1.06069486e-02, 1.45578106e-03, 3.16699953e-04,\n",
       "        8.87722667e-03, 5.54114510e-03]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
